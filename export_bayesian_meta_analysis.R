# ============================================================================
# BAYESIAN TTE META-ANALYSIS EXPORT FOR DJANGO
# Complete Bayesian Analysis with Stan/CmdStanR like Original Implementation
# ============================================================================

# Load required libraries
required_packages <- c("tidyverse", "jsonlite", "openxlsx")

for (pkg in required_packages) {
  if (!require(pkg, character.only = TRUE)) {
    cat("Installing package:", pkg, "\n")
    install.packages(pkg, dependencies = TRUE)
    library(pkg, character.only = TRUE)
  }
}

# ============================================================================
# STAN INTERFACE SETUP (FROM YOUR ORIGINAL SCRIPT)
# ============================================================================

# Choose Stan interface
use_cmdstanr = TRUE

# Function to setup CmdStanR
setup_cmdstanr <- function() {
  if (!require("cmdstanr", character.only = TRUE)) {
    cat("Installing cmdstanr from GitHub...\n")
    if (!require("remotes", character.only = TRUE)) {
      install.packages("remotes")
      library(remotes)
    }
    remotes::install_github("stan-dev/cmdstanr")
    library(cmdstanr)
  }
  
  # Check if CmdStan is installed
  tryCatch({
    version = cmdstanr::cmdstan_version(error_on_NA = FALSE)
    if (is.na(version)) {
      cat("CmdStan not found. Installing CmdStan...\n")
      cmdstanr::install_cmdstan(cores = parallel::detectCores())
      cat("CmdStan installation complete.\n")
    } else {
      cat("CmdStan found. Version:", version, "\n")
    }
  }, error = function(e) {
    cat("CmdStan not found. Installing CmdStan...\n")
    cmdstanr::install_cmdstan(cores = parallel::detectCores())
    cat("CmdStan installation complete.\n")
  })
}

# Function to setup RStan
setup_rstan <- function() {
  if (!require("rstan", character.only = TRUE)) {
    cat("Installing rstan...\n")
    install.packages("rstan", dependencies = TRUE)
    library(rstan)
  }
  rstan_options(auto_write = TRUE)
}

# Setup Stan interface
if (use_cmdstanr) {
  cat("Setting up CmdStanR interface...\n")
  tryCatch({
    setup_cmdstanr()
    library(cmdstanr)
    library(posterior)
    library(bayesplot)
    options(mc.cores = parallel::detectCores())
    stan_ready <- TRUE
  }, error = function(e) {
    cat("CmdStanR setup failed, falling back to RStan...\n")
    use_cmdstanr <- FALSE
    stan_ready <- FALSE
  })
} 

if (!use_cmdstanr || !exists("stan_ready") || !stan_ready) {
  cat("Setting up RStan interface...\n")
  tryCatch({
    setup_rstan()
    library(rstan)
    library(bayesplot)
    options(mc.cores = parallel::detectCores())
    stan_ready <- TRUE
  }, error = function(e) {
    cat("Stan setup completely failed. Will use simplified analysis.\n")
    stan_ready <- FALSE
  })
}

# ============================================================================
# LOAD DATA
# ============================================================================

cat("Loading TTE meta-research dataset for Bayesian analysis...\n")

# Create data directory if it doesn't exist
dir.create("ttedb/data", recursive = TRUE, showWarnings = FALSE)

# Load the original data (CSV format)
study_chars_file <- "dataset/TTE_Metaresearch_Clean_Dataset - Studies characteristics.csv"
picos_file <- "dataset/TTE_Metaresearch_Clean_Dataset - PICOs.csv"

if (!file.exists(study_chars_file) || !file.exists(picos_file)) {
  cat("ERROR: Data files not found:\n")
  cat("-", study_chars_file, "\n")
  cat("-", picos_file, "\n")
  quit(status = 1)
}

# Load data
study_chars <- read.csv(study_chars_file)
picos <- read.csv(picos_file)

cat(sprintf("Data loaded: %d studies, %d comparisons\n", 
           nrow(study_chars), nrow(picos)))

# ============================================================================
# BAYESIAN DATA PREPARATION (FROM YOUR ORIGINAL SCRIPT)
# ============================================================================

cat("Preparing data for Bayesian meta-analysis...\n")

# Enhanced data preparation function (simplified from your original)
prepare_bayesian_data = function(tte_picos, study_chars) {
  clean_data = tte_picos %>%
    filter(
      # Check for non-missing values
      !is.na(rct_estimate),
      !is.na(tte_estimate),
      !is.na(rct_lb),
      !is.na(rct_ub),
      !is.na(tte_lb),
      !is.na(tte_ub),
      !is.na(effect_measure),
      
      # Check for positive values in ratio measures
      !(effect_measure %in% c("HR", "OR", "RR") &
        (rct_estimate <= 0 | tte_estimate <= 0 |
         rct_lb <= 0 | rct_ub <= 0 |
         tte_lb <= 0 | tte_ub <= 0)),
      
      # Check for finite values
      is.finite(rct_estimate),
      is.finite(tte_estimate),
      is.finite(rct_lb),
      is.finite(rct_ub),
      is.finite(tte_lb),
      is.finite(tte_ub),
      
      # Check that confidence intervals make sense
      rct_lb < rct_ub,
      tte_lb < tte_ub,
      rct_lb <= rct_estimate,
      rct_estimate <= rct_ub,
      tte_lb <= tte_estimate,
      tte_estimate <= tte_ub
    ) %>%
    
    # Calculate standard errors from confidence intervals
    mutate(
      # For RCT estimates
      rct_se = case_when(
        effect_measure %in% c("HR", "OR", "RR") ~
          (log(rct_ub) - log(rct_lb)) / (2 * qnorm(0.975)),
        TRUE ~ (rct_ub - rct_lb) / (2 * qnorm(0.975))
      ),
      
      # For TTE estimates
      tte_se = case_when(
        effect_measure %in% c("HR", "OR", "RR") ~
          (log(tte_ub) - log(tte_lb)) / (2 * qnorm(0.975)),
        TRUE ~ (tte_ub - tte_lb) / (2 * qnorm(0.975))
      ),
      
      # Calculate differences on appropriate scales
      diff_estimate = case_when(
        effect_measure %in% c("HR", "OR", "RR") ~
          log(tte_estimate) - log(rct_estimate),
        TRUE ~ tte_estimate - rct_estimate
      ),
      
      # Standard error of differences
      diff_se = sqrt(rct_se^2 + tte_se^2),
      
      # Create measure type indicators
      measure_type = factor(
        effect_measure,
        levels = c("HR", "OR", "RR", "RD", "MD", "SMD")
      ),
      measure_idx = as.numeric(measure_type),
      
      # Use default sample sizes (can be improved later)
      total_n_tte = 1000,
      total_n_rct = 1000
    ) %>%
    
    # Remove rows with invalid calculations
    filter(
      is.finite(rct_se),
      is.finite(tte_se),
      is.finite(diff_estimate),
      is.finite(diff_se),
      rct_se > 0,
      tte_se > 0,
      diff_se > 0
    ) %>%
    
    # Remove extreme outliers (>5 SDs from mean within each measure type)
    group_by(effect_measure) %>%
    mutate(
      z_score = abs(diff_estimate - mean(diff_estimate, na.rm = TRUE)) /
        sd(diff_estimate, na.rm = TRUE)
    ) %>%
    filter(z_score <= 5 | is.na(z_score)) %>%
    ungroup() %>%
    
    # Ensure we have sufficient data per measure type
    group_by(effect_measure) %>%
    filter(n() >= 3) %>%
    ungroup()
  
  cat("Data cleaning summary:\n")
  cat("- Original rows:", nrow(tte_picos), "\n")
  cat("- Clean rows:", nrow(clean_data), "\n")
  cat("- Effect measures:", paste(unique(clean_data$effect_measure), collapse = ", "), "\n")
  
  return(clean_data)
}

# Clean the data
clean_picos <- prepare_bayesian_data(picos, study_chars)

# ============================================================================
# BAYESIAN META-ANALYSIS STAN MODEL
# ============================================================================

# Stan model for stratified Bayesian meta-analysis (updated syntax)
stan_model_code <- "
data {
  int<lower=0> N;                    // number of studies
  int<lower=0> K;                    // number of effect measure types
  vector[N] y;                       // observed differences
  vector<lower=0>[N] se;             // standard errors
  array[N] int<lower=1,upper=K> measure;   // effect measure type indicator
}

parameters {
  vector[K] mu;                      // mean effect for each measure type
  vector<lower=0>[K] tau;            // between-study SD for each measure type
  vector[N] theta;                   // study-specific effects
}

model {
  // Priors
  mu ~ normal(0, 1);
  tau ~ normal(0, 0.5);
  
  // Hierarchical model
  for (n in 1:N) {
    theta[n] ~ normal(mu[measure[n]], tau[measure[n]]);
    y[n] ~ normal(theta[n], se[n]);
  }
}

generated quantities {
  vector[K] mu_exp;                  // exponentiated effects for ratio measures
  vector[K] tau_squared;             // tau squared
  
  for (k in 1:K) {
    mu_exp[k] = exp(mu[k]);
    tau_squared[k] = tau[k]^2;
  }
}
"

# ============================================================================
# RUN BAYESIAN META-ANALYSIS
# ============================================================================

# Initialize results variables
bayesian_results <- NULL
subgroup_results <- list()

if (exists("stan_ready") && stan_ready && nrow(clean_picos) > 0) {
  cat("Running Bayesian meta-analysis with Stan...\n")
  
  tryCatch({
    # Prepare data for Stan
    effect_measures <- unique(clean_picos$effect_measure)
    measure_map <- setNames(1:length(effect_measures), effect_measures)
    
    stan_data <- list(
      N = nrow(clean_picos),
      K = length(effect_measures),
      y = clean_picos$diff_estimate,
      se = clean_picos$diff_se,
      measure = as.numeric(factor(clean_picos$effect_measure, levels = effect_measures))
    )
    
    cat("Stan data prepared: N =", stan_data$N, ", K =", stan_data$K, "\n")
    
    # Fit the model
    if (use_cmdstanr) {
      # Write Stan model to file
      writeLines(stan_model_code, "bayesian_meta_model.stan")
      model <- cmdstan_model("bayesian_meta_model.stan")
      
      fit <- model$sample(
        data = stan_data,
        chains = 4,
        parallel_chains = 4,
        iter_warmup = 50000,
        iter_sampling = 50000,
        refresh = 500
      )
      
      # Extract results
      draws <- fit$draws()
      summary_stats <- fit$summary()
      
    } else {
      # Use RStan
      fit <- stan(
        model_code = stan_model_code,
        data = stan_data,
        chains = 4,
        iter = 3000,
        warmup = 1000,
        cores = 4
      )
      
      # Extract results
      draws <- extract(fit)
      summary_stats <- summary(fit)$summary
    }
    
    cat("‚úÖ Bayesian meta-analysis completed successfully!\n")
    
    # ============================================================================
    # EXTRACT BAYESIAN RESULTS
    # ============================================================================
    
    bayesian_results <- list()
    
    for (i in 1:length(effect_measures)) {
      measure <- effect_measures[i]
      
      # Extract posterior samples
      if (use_cmdstanr) {
        mu_samples <- draws[,, paste0("mu[", i, "]")]
        tau_samples <- draws[,, paste0("tau[", i, "]")]
        tau_sq_samples <- draws[,, paste0("tau_squared[", i, "]")]
      } else {
        mu_samples <- draws$mu[, i]
        tau_samples <- draws$tau[, i]
        tau_sq_samples <- tau_samples^2
      }
      
      # Calculate summary statistics
      mu_mean <- mean(mu_samples)
      mu_ci <- quantile(mu_samples, c(0.025, 0.975))
      mu_pred <- quantile(mu_samples + rnorm(length(mu_samples), 0, tau_samples), c(0.025, 0.975))
      
      tau_sq_mean <- mean(tau_sq_samples)
      tau_mean <- mean(tau_samples)
      
      # Calculate I-squared approximation
      measure_data <- clean_picos %>% filter(effect_measure == measure)
      typical_se <- median(measure_data$diff_se)
      i_squared <- (tau_sq_mean / (tau_sq_mean + typical_se^2)) * 100
      
      bayesian_results[[measure]] <- list(
        effect_measure = measure,
        n_studies = nrow(measure_data),
        pooled_estimate = mu_mean,
        ci_lower = mu_ci[1],
        ci_upper = mu_ci[2],
        prediction_lower = mu_pred[1],
        prediction_upper = mu_pred[2],
        tau_squared = tau_sq_mean,
        tau = tau_mean,
        i_squared = max(0, i_squared),
        total_sample_size = sum(measure_data$total_n_tte, na.rm = TRUE),
        method = "Bayesian hierarchical meta-analysis",
        estimation = "CmdStanR/RStan with 4 chains, 50000 iterations"
      )
      
      cat(sprintf("‚úÖ %s: %d studies, Œº = %.3f [%.3f, %.3f], œÑ¬≤ = %.4f, I¬≤ ‚âà %.1f%%\n",
                  measure, bayesian_results[[measure]]$n_studies, 
                  mu_mean, mu_ci[1], mu_ci[2], tau_sq_mean, i_squared))
    }
    
    # Export Bayesian results
    write_json(bayesian_results, "ttedb/data/meta_analysis_results.json", 
               pretty = TRUE, auto_unbox = TRUE)
    
    cat("‚úÖ Bayesian meta-analysis results exported!\n")
    
    # ============================================================================
    # SUBGROUP ANALYSES (Like your original script)
    # ============================================================================
    
    cat("Running Bayesian subgroup analyses...\n")
    
    subgroup_results <- list()
    
    # Add disease categories to clean data
    clean_picos_with_chars <- clean_picos %>%
      left_join(study_chars %>% 
                select(study_id, disease_category, data_type, year), 
                by = "study_id") %>%
      mutate(
        disease_cat_clean = case_when(
          str_detect(tolower(disease_category), "cardio|heart") ~ "Cardiovascular",
          str_detect(tolower(disease_category), "cancer|oncology") ~ "Oncology", 
          str_detect(tolower(disease_category), "infection|covid") ~ "Infectious",
          str_detect(tolower(disease_category), "neuro|brain") ~ "Neurological",
          TRUE ~ "Other"
        ),
        data_source_clean = case_when(
          str_detect(tolower(data_type), "ehr|electronic") ~ "EHR",
          str_detect(tolower(data_type), "claims") ~ "Claims",
          str_detect(tolower(data_type), "registry") ~ "Registry",
          TRUE ~ "Other"
        ),
        time_period = case_when(
          year <= 2020 ~ "2016-2020",
          year <= 2022 ~ "2021-2022", 
          TRUE ~ "2023-2024"
        )
      )
    
    # Subgroup analysis by disease category
    tryCatch({
      disease_categories <- unique(clean_picos_with_chars$disease_cat_clean)
      disease_categories <- disease_categories[!is.na(disease_categories)]
      
      for (disease in disease_categories) {
        disease_data <- clean_picos_with_chars %>% 
          filter(disease_cat_clean == disease)
        
        if (nrow(disease_data) >= 5) {  # Minimum studies for subgroup
          
          # Prepare Stan data for this subgroup
          disease_measures <- unique(disease_data$effect_measure)
          disease_stan_data <- list(
            N = nrow(disease_data),
            K = length(disease_measures),
            y = disease_data$diff_estimate,
            se = disease_data$diff_se,
            measure = as.numeric(factor(disease_data$effect_measure, levels = disease_measures))
          )
          
          # Fit subgroup model (simplified for speed)
          if (use_cmdstanr) {
            subgroup_fit <- model$sample(
              data = disease_stan_data,
              chains = 2,
              parallel_chains = 2,
              iter_warmup = 500,
              iter_sampling = 1000,
              refresh = 0
            )
            subgroup_draws <- subgroup_fit$draws()
          } else {
            subgroup_fit <- stan(
              model_code = stan_model_code,
              data = disease_stan_data,
              chains = 2,
              iter = 1500,
              warmup = 500,
              cores = 2,
              verbose = FALSE
            )
            subgroup_draws <- extract(subgroup_fit)
          }
          
          # Extract subgroup results
          disease_results <- list()
          for (i in 1:length(disease_measures)) {
            measure <- disease_measures[i]
            
            if (use_cmdstanr) {
              mu_samples <- subgroup_draws[,, paste0("mu[", i, "]")]
            } else {
              mu_samples <- subgroup_draws$mu[, i]
            }
            
            mu_mean <- mean(mu_samples)
            mu_ci <- quantile(mu_samples, c(0.025, 0.975))
            
            disease_results[[measure]] <- list(
              pooled_estimate = mu_mean,
              ci_lower = mu_ci[1],
              ci_upper = mu_ci[2],
              n_studies = sum(disease_data$effect_measure == measure)
            )
          }
          
          subgroup_results[["disease"]][[disease]] <- disease_results
          cat(sprintf("‚úÖ Disease subgroup '%s': %d studies\n", disease, nrow(disease_data)))
        }
      }
      
    }, error = function(e) {
      cat("‚ö†Ô∏è Disease subgroup analysis failed:", e$message, "\n")
    })
    
    # Subgroup analysis by data source
    tryCatch({
      data_sources <- unique(clean_picos_with_chars$data_source_clean)
      data_sources <- data_sources[!is.na(data_sources)]
      
      for (source in data_sources) {
        source_data <- clean_picos_with_chars %>% 
          filter(data_source_clean == source)
        
        if (nrow(source_data) >= 5) {
          # Similar analysis as disease subgroups
          source_measures <- unique(source_data$effect_measure)
          source_stan_data <- list(
            N = nrow(source_data),
            K = length(source_measures),
            y = source_data$diff_estimate,
            se = source_data$diff_se,
            measure = as.numeric(factor(source_data$effect_measure, levels = source_measures))
          )
          
          if (use_cmdstanr) {
            source_fit <- model$sample(
              data = source_stan_data,
              chains = 2,
              iter_warmup = 500,
              iter_sampling = 1000,
              refresh = 0
            )
            source_draws <- source_fit$draws()
          } else {
            source_fit <- stan(
              model_code = stan_model_code,
              data = source_stan_data,
              chains = 2,
              iter = 1500,
              warmup = 500,
              cores = 2,
              verbose = FALSE
            )
            source_draws <- extract(source_fit)
          }
          
          source_results <- list()
          for (i in 1:length(source_measures)) {
            measure <- source_measures[i]
            
            if (use_cmdstanr) {
              mu_samples <- source_draws[,, paste0("mu[", i, "]")]
            } else {
              mu_samples <- source_draws$mu[, i]
            }
            
            mu_mean <- mean(mu_samples)
            mu_ci <- quantile(mu_samples, c(0.025, 0.975))
            
            source_results[[measure]] <- list(
              pooled_estimate = mu_mean,
              ci_lower = mu_ci[1],
              ci_upper = mu_ci[2],
              n_studies = sum(source_data$effect_measure == measure)
            )
          }
          
          subgroup_results[["data_source"]][[source]] <- source_results
          cat(sprintf("‚úÖ Data source subgroup '%s': %d studies\n", source, nrow(source_data)))
        }
      }
      
    }, error = function(e) {
      cat("‚ö†Ô∏è Data source subgroup analysis failed:", e$message, "\n")
    })
    
    # Export subgroup results if any were successful
    if (length(subgroup_results) > 0) {
      write_json(subgroup_results, "ttedb/data/subgroup_analysis_results.json", 
                 pretty = TRUE, auto_unbox = TRUE)
      cat("‚úÖ Bayesian subgroup analyses exported!\n")
    }
    
  }, error = function(e) {
    cat("‚ö†Ô∏è Bayesian analysis failed:", e$message, "\n")
    cat("Falling back to basic export...\n")
    bayesian_results <<- NULL
    subgroup_results <<- list()
  })
  
} else {
  cat("‚ö†Ô∏è Stan not available or no clean data. Using basic export only.\n")
  bayesian_results <- NULL
  subgroup_results <- list()
}

# ============================================================================
# CREATE ENHANCED FOREST PLOT DATA WITH BAYESIAN RESULTS
# ============================================================================

cat("Creating enhanced forest plot data...\n")

real_forest_data <- list()

for (measure in unique(clean_picos$effect_measure)) {
  measure_data <- clean_picos %>%
    filter(effect_measure == measure) %>%
    mutate(
      author = coalesce(first_author, paste("Study", row_number())),
      study_label = paste(author, year),
      point_estimate = diff_estimate,
      lower_ci = diff_estimate - 1.96 * diff_se,
      upper_ci = diff_estimate + 1.96 * diff_se,
      sample_size = total_n_tte,
      tte_estimate = tte_estimate,
      rct_estimate = rct_estimate,
      target_trial_name = coalesce(target_trial_name, "Target Trial")
    ) %>%
    select(study_id, author, year, study_label, point_estimate, lower_ci, upper_ci, 
           sample_size, tte_estimate, rct_estimate, target_trial_name)
  
  if (nrow(measure_data) > 0) {
    real_forest_data[[tolower(measure)]] <- measure_data
  }
}

# Export forest plot data
write_json(real_forest_data, "ttedb/data/forest_plot_data.json", 
           pretty = TRUE, auto_unbox = TRUE)

# ============================================================================
# CREATE COMPREHENSIVE EXPORT SUMMARY
# ============================================================================

# Load basic descriptive data (with fallback)
if (file.exists("ttedb/data/descriptive_results.json")) {
  descriptive_data <- fromJSON("ttedb/data/descriptive_results.json")
} else {
  # Create basic descriptive data if not available
  cat("Creating basic descriptive data...\n")
  dir.create("ttedb/data", recursive = TRUE, showWarnings = FALSE)
  
  descriptive_data <- list(
    overview = list(
      total_studies = nrow(study_chars),
      total_comparisons = nrow(picos),
      effect_measures = unique(clean_picos$effect_measure),
      studies_with_clean_data = nrow(clean_picos)
    )
  )
  
  write_json(descriptive_data, "ttedb/data/descriptive_results.json", 
             pretty = TRUE, auto_unbox = TRUE)
}

export_summary <- list(
  export_timestamp = Sys.time(),
  data_source = c(study_chars_file, picos_file),
  total_studies = descriptive_data$overview$total_studies,
  total_comparisons = descriptive_data$overview$total_comparisons,
  bayesian_analysis_performed = !is.null(bayesian_results),
  subgroup_analysis_performed = exists("subgroup_results") && length(subgroup_results) > 0,
  stan_interface = if(use_cmdstanr) "CmdStanR" else "RStan",
  effect_measures = if(!is.null(bayesian_results)) names(bayesian_results) else unique(clean_picos$effect_measure),
  studies_in_meta_analysis = nrow(clean_picos),
  files_created = c(
    "ttedb/data/descriptive_results.json",
    "ttedb/data/forest_plot_data.json",
    if(!is.null(bayesian_results)) "ttedb/data/meta_analysis_results.json",
    if(exists("subgroup_results") && length(subgroup_results) > 0) "ttedb/data/subgroup_analysis_results.json"
  ),
  export_type = "complete_bayesian_with_subgroups",
  notes = paste(
    if(!is.null(bayesian_results)) "‚úÖ Bayesian hierarchical meta-analysis" else "‚ùå Bayesian analysis failed",
    if(exists("subgroup_results") && length(subgroup_results) > 0) "‚úÖ Subgroup analyses" else "‚ùå Subgroup analyses failed",
    sep = " | "
  )
)

write_json(export_summary, "ttedb/data/export_summary.json", 
           pretty = TRUE, auto_unbox = TRUE)

cat("\n", paste(rep("=", 80), collapse=""), "\n")
cat("üéØ BAYESIAN TTE META-ANALYSIS EXPORT COMPLETE!\n")
cat(paste(rep("=", 80), collapse=""), "\n")
cat("Files created:\n")
cat("‚úÖ ttedb/data/descriptive_results.json (real descriptive statistics)\n")
cat("‚úÖ ttedb/data/forest_plot_data.json (real individual study data)\n")
if (!is.null(bayesian_results)) {
  cat("‚úÖ ttedb/data/meta_analysis_results.json (Bayesian meta-analysis results)\n")
}
if (exists("subgroup_results") && length(subgroup_results) > 0) {
  cat("‚úÖ ttedb/data/subgroup_analysis_results.json (Bayesian subgroup analyses)\n")
}
cat("‚úÖ ttedb/data/export_summary.json (export metadata)\n")

if (!is.null(bayesian_results)) {
  cat("\nüî¨ BAYESIAN META-ANALYSIS SUMMARY:\n")
  for (measure in names(bayesian_results)) {
    result <- bayesian_results[[measure]]
    cat(sprintf("üìä %s: %d studies, Œº = %.3f [%.3f, %.3f], œÑ¬≤ = %.4f\n",
                measure, result$n_studies, result$pooled_estimate,
                result$ci_lower, result$ci_upper, result$tau_squared))
  }
}

if (exists("subgroup_results") && length(subgroup_results) > 0) {
  cat("\nüîç SUBGROUP ANALYSES COMPLETED:\n")
  if ("disease" %in% names(subgroup_results)) {
    cat("üìä Disease categories:", paste(names(subgroup_results$disease), collapse = ", "), "\n")
  }
  if ("data_source" %in% names(subgroup_results)) {
    cat("üìä Data sources:", paste(names(subgroup_results$data_source), collapse = ", "), "\n")
  }
}

cat("\nYour Django website will now show REAL Bayesian meta-analysis results! üéØ‚ú®\n")
cat(paste(rep("=", 80), collapse=""), "\n")